name: Sales Scraper

on:
  schedule:
    # Run every 6 hours at minutes 0 (00:00, 06:00, 12:00, 18:00 UTC)name: Sales Scraper

on:
  schedule:
    # Runs at a random minute between 5 and 15, every 6 hours.
    - cron: '5-15/10 */6 * * *'
    # Runs daily at a random minute between 50 and 59 past 11 UTC.
    - cron: '50-59/5 11 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create Google credentials file
      run: |
        echo '${{ secrets.GOOGLE_CREDENTIALS }}' > credentials.json

    # --- UPDATED --- This now passes the PROXY_URL from your GitHub Secrets.
    - name: Create .env file
      run: |
        echo "GOOGLE_SHEET_ID=${{ secrets.GOOGLE_SHEET_ID }}" >> .env
        echo "PROXY_URL=${{ secrets.PROXY_URL }}" >> .env

    - name: Run scraper
      run: |
        python chatgptversionscraper_github.py
    - cron: '0 */6 * * *'
  
  # Allow manual trigger
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Install Chrome and ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver
    
    - name: Create Google credentials file
      run: |
        echo '${{ secrets.GOOGLE_CREDENTIALS }}' > credentials.json
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
    
    - name: Create .env file
      run: |
        echo "GOOGLE_SHEET_ID=${{ secrets.GOOGLE_SHEET_ID }}" >> .env
        echo "GOOGLE_DRIVE_FOLDER_ID=${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}" >> .env
      env:
        GOOGLE_SHEET_ID: ${{ secrets.GOOGLE_SHEET_ID }}
        GOOGLE_DRIVE_FOLDER_ID: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}
    
    - name: Run scraper
      run: |
        python chatgptversionscraper_github.py
    
    - name: Upload logs as artifacts (if any errors)
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs
        path: |
          *.log
          *.html
          *.png
        retention-days: 7
